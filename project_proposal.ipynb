{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Proposal\n",
    "\n",
    "## The Fur-ppenheimer\n",
    "\n",
    "### Project Summary\n",
    "In 1936, Meret Oppenheim created a surrealist piece of art that has stuck in my mind since the moment I saw it. A teacup, saucer, and spoon covered in fur. Such a simple concept, but so strikingly bizarre. \n",
    "\n",
    "![teacup](https://media.npr.org/assets/img/2016/02/09/meretoppenheim_custom-f67c923f4675bdfcf948d4c7f725ce32cd271f52.jpg)\n",
    "\n",
    "This piece of art begs the question, what do other objects look like covered in fur? Normal? More Cozy? Perhaps even more bizarre than this teacup and saucer? This leads me to my project proposal. I want to create a model that covers objects in fur. My plan for doing this is to use some kind of object identification network to identify the object to be fur-covered and a style transfer network to cover it in fur. I have no idea if this plan is going to work but at the very least I will learn to work with two different neural network architectures. \n",
    "\n",
    "### Resources\n",
    "##### Blog Posts\n",
    "\n",
    "* [An overview of semantic image segmentation](https://www.jeremyjordan.me/semantic-segmentation/)\n",
    "* [Semantic segmentation using torchvision](https://learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/)\n",
    "* [A 2021 guide to Semantic Segmentation](https://nanonets.com/blog/semantic-image-segmentation-2020/)\n",
    "* [Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "* [Neural Transfer Using Pytorch](https://pytorch.org/tutorials/advanced/neural_style_tutorial.html)\n",
    "* [torchvision 0.3: segmentation, detection models, new datasets and more..](https://pytorch.org/blog/torchvision03/)\n",
    "* [Image Segmentation](https://learnopencv.com/image-segmentation/)\n",
    "\n",
    "\n",
    "##### Packages\n",
    "* PIL\n",
    "* Pytorch\n",
    "* torchvision\n",
    "* matplotlib\n",
    "\n",
    "##### Pre-trained models\n",
    "* [Pytorch semantic segmentation](https://pytorch.org/vision/stable/models.html#semantic-segmentation)\n",
    "* [PyTorch-Style-Transfer](https://github.com/zhanghang1989/PyTorch-Multi-Style-Transfer#stylize-images-using-pre-trained-msg-net)\n",
    "\n",
    "##### Literature\n",
    "* [A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf)\n",
    "* [Mask R-CNN](https://research.fb.com/wp-content/uploads/2017/08/maskrcnn.pdf)\n",
    "\n",
    "### Initial Tasks\n",
    "The first thing I want to do is get the semantic segmentation network working.\n",
    "\n",
    "### Going beyond available resources\n",
    "The available resources provide instructions and pre-trained networks to do semantic segmentation and style transfer. I want to combine these two methods in a novel way to create furry objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "To start, I wanted to explore the options available to me for image segmentation \n",
    "(my exploration can be found in Image_Segmentation.ipynb). I want to apply the style transfer to only one object in an image (leaving the background as is). To do this, I need to be able to identify objects in an image (which is where image segmentation comes in). I started off by exploring semantic segmentation. To do this, I followed [this](https://learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/) tutorial and I used the pretrained Fully Convolutional Network ( FCN ) network for image segmentation provided by torchvision. I quickly ran into problems when I realized that there are 21 classes that this model is able to identify and if I wanted to use an object that wasn't a class (for example a teacup) this option was not going to work. \n",
    "\n",
    "I also tried using the fully trained Mask R-CNN model for Object Detection provided by torchvision. This model is definitely more flexible than semantic segmentation because it isn't looking for specific classes of objects and instead just returns masks of identified objects. The only problem that is that it identifies more objects than are necessary and requires manual review to identify the appopriate mask for the object in question. Given that I don't need to create a ton of images, a manual review process is acceptable so I think I will use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
